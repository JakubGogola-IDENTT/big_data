{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 18.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_words(words):\n",
    "    filtered_words = [word.lower().translate(str.maketrans('','', punctuation)) for word in words]\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/cobc.txt') as f:\n",
    "    data1 = [word for line in f for word in line.split()]\n",
    "    data1 = process_words(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/lotr.txt') as f:\n",
    "    data2 = [word for line in f for word in line.split()]\n",
    "    data2 = process_words(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shingles(text):\n",
    "    shingles = []\n",
    "\n",
    "    for i in range(len(text)):\n",
    "        shingle = []\n",
    "\n",
    "        if i + 7 >= len(text):\n",
    "            break\n",
    "\n",
    "        for j in range(i, i+7):\n",
    "            shingle.append(text[j])\n",
    "\n",
    "        shingles.append(' '.join(shingle))\n",
    "        \n",
    "    return shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "shingles1 = get_shingles(data1)\n",
    "shingles2 = get_shingles(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinHash:\n",
    "    def __init__(self, k, seed=10):\n",
    "        self._k = k\n",
    "        self._seed = seed\n",
    "        \n",
    "        min_int = np.iinfo(np.int64).min\n",
    "        max_int = np.iinfo(np.int64).max\n",
    "        \n",
    "        self._masks = np.random.RandomState(seed=self._seed).randint(min_int, max_int, self._k)\n",
    "        \n",
    "        self._hashes = np.empty(self._k, dtype=np.int64)\n",
    "        self._hashes.fill(max_int)\n",
    "        \n",
    "    def add(self, v):\n",
    "        hashes = np.bitwise_xor(self._masks, hash(v))\n",
    "        self._hashes = np.minimum(self._hashes, hashes)\n",
    "        \n",
    "    def jaccard(self, other):\n",
    "        if np.any(self._masks != other._masks):\n",
    "            raise Exception('Can only calculate similarity between min-hashes with the same hash functions!')\n",
    "            \n",
    "        return (self._hashes == other._hashes).sum() / float(self._k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
