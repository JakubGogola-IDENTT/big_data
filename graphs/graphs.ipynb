{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import findspark as fs\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.init()\n",
    "sc = SparkContext(appName=\"Graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate file with graph\n",
    "vertices = random.randint(100, 1000)\n",
    "\n",
    "with open('./data/graph.txt', 'w') as f:\n",
    "    f.write('[\\n')\n",
    "    for v in range(1, vertices+1):\n",
    "        neighbours = []\n",
    "        neighbours_count = random.randint(1, 10)\n",
    "\n",
    "        while len(neighbours) < neighbours_count:\n",
    "            next = random.randint(1, vertices)\n",
    "            \n",
    "            if next not in neighbours:\n",
    "                neighbours.append(next)\n",
    "        \n",
    "        neighbours.sort()\n",
    "        \n",
    "        f.write(str([v, neighbours]) + ',\\n')\n",
    "    \n",
    "    f.write(']\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges(row):\n",
    "    res = re.search(r'\\[(\\d+), \\[([\\d, ]+)\\]\\]', row)\n",
    "    print(res)\n",
    "    return (res.group(1), res.group(2).split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('142', '1'), (' 186', '1'), (' 188', '1'), (' 368', '1'), (' 380', '1'), ('53', '2'), (' 125', '2'), (' 151', '2'), (' 265', '2'), (' 266', '2')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(' 10', ['185']),\n",
       " (' 100', ['76', '242', '287', '289', '394', '450']),\n",
       " (' 101', ['54', '90', '150', '218', '262']),\n",
       " (' 102', ['96', '280', '361', '376']),\n",
       " (' 103', ['85', '228', '271', '307', '446']),\n",
       " (' 104', ['83', '186', '209', '398']),\n",
       " (' 105', ['8', '46', '73', '269', '276', '423']),\n",
       " (' 106', ['83', '312']),\n",
       " (' 107', ['157', '208', '214', '440']),\n",
       " (' 108', ['18', '38', '41', '59', '82', '111', '196', '299', '312'])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = sc.textFile('./data/graph.txt').filter(lambda row: ',' in row).map(get_edges)\n",
    "mapped = edges.flatMap(lambda pair: [(v, pair[0]) for v in pair[1]])\n",
    "groupped = mapped.groupByKey().map(lambda pair: (pair[0], list(pair[1]))).sortByKey()\n",
    "groupped.collect()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_vertices(row):\n",
    "    splitted = row.split()\n",
    "    return (splitted[0], splitted[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = sc.textFile('./data/stanford_graph.txt').map(map_vertices) # (v1 -> v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_out_pairs = edges.flatMap(lambda pair: [(pair[0], 'out'), (pair[1], 'in')]) # [(v1, 'out'), (v2, 'in')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "counted_pairs = in_out_pairs.map(lambda x: (x, 1)).reduceByKey(lambda a, b: a + b) # ((v, 'out/in'), 1) -> aggregate by key ((v, 'out/in'), m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pairs = counted_pairs.sortBy(lambda pair: pair[0][1], ascending=True) # ['in', 'in', ..., 'out', 'out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_with_edge_as_key = sorted_pairs.map(lambda pair: (pair[0][0], (pair[0][1], pair[1]))) # (v, ('in/out', n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pairs = pairs_with_edge_as_key.groupByKey() # (v, [('in', n), ('out', m)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet(pair):\n",
    "    counted = list(pair[1])\n",
    "    \n",
    "    if len(counted) == 2:\n",
    "        return (pair[0], counted[0][1], counted[1][1])\n",
    "    elif counted[0][0] == 'in':\n",
    "        return (pair[0], counted[0][1], 0)\n",
    "    else:\n",
    "        return (pair[0], 0, counted[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('15409', 3, 1),\n",
       " ('17794', 2, 1),\n",
       " ('25202', 2, 1),\n",
       " ('53625', 2, 1),\n",
       " ('54582', 2, 1)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertices_set = grouped_pairs.map(get_triplet) # (v, n, m)\n",
    "vertices_set.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.203165627893243"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_vertices = vertices_set.map(lambda x: (x[1], 1))\n",
    "mapped_vertices.reduce(lambda a, b: ((a[0] * a[1] + b[0] * b[1]) / (a[1] + b[1]), a[1] + b[1]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.2031656278933"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_vertices = vertices_set.map(lambda x: (x[2], 1))\n",
    "mapped_vertices.reduce(lambda a, b: ((a[0] * a[1] + b[0] * b[1]) / (a[1] + b[1]), a[1] + b[1]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
